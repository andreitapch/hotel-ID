{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport os\nimport sys\n\nimport torch\nimport fastai\nfrom fastai.imports import *\nfrom fastai.vision import *\nfrom fastai.vision.all import *\nfrom torchvision.models import vgg16_bn\nfrom torchvision import datasets, transforms\n\nimport PIL\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib import image\nfrom matplotlib.pyplot import imshow\nfrom sklearn import preprocessing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Defining Directories\nwork_dir = Path('/kaggle/working/')\npath = Path('../input/hotel-id-2021-fgvc8')\ntrain = path/ '/train_images'\ntest =  path/'/test_images'\nsample_sub = path/'sample_submission.csv'\nlabels = path/'train.csv'\n\n## Reading csv\ntrain_data = pd.read_csv(labels)\ndf_sample = pd.read_csv(sample_sub)\n\ntrain_data.head()\ntrain_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.columns\nlen_data = len(train_data['hotel_id'].value_counts())\n\nprint(\"data Length:\", len_data)\nprint(\"Hotel Chains:\",train_data['chain'].unique())\nchain_len = len(train_data['chain'].unique())-1\nchain_len\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hotels per Chain \nhotel_per_chain={}\nchains = train_data['chain'].unique()\nfor chain_id in chains:\n    hotel_per_chain[chain_id] = train_data[train_data['chain']==chain_id]['hotel_id'].nunique()\n\n#plot\nbar = plt.bar(x=hotel_per_chain.keys(),height=hotel_per_chain.values())\nplt.xlabel(\"Chain ID\")\nplt.ylabel(\"Count\")\nplt.title(\"Hotels per Chain\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Images per Hotel\nimage_per_hotel=[]\nhotels_id = train_data['hotel_id'].unique()\nfor hotel_id in hotels_id:\n    image_per_hotel.append(train_data[train_data['hotel_id']==hotel_id]['image'].nunique())\n#     print(image_per_hotel)\n  \nhotel_image_df = pd.DataFrame({\"hotel_id\":map(str,hotels_id),\"image_count\":image_per_hotel})\nhotel_image_df.sort_values(by=\"image_count\",ascending=False,inplace=True)  \n\nplt.figure(figsize=[15,15])\n\nplt.bar(x=hotel_image_df[\"hotel_id\"],height=hotel_image_df[\"image_count\"])\nplt.xlabel(\"Hotel ID\")\n# plt.xticks(rotation=45)\nplt.ylabel(\"Image Count\")\n# plt.title(\"Hotel and their image count (Top 50)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label_enc = preprocessing.LabelEncoder().fit(train_data['hotel_id'])\n# train_data['label'] = label_enc.transform(train_data['hotel_id'])\n# train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_loader(img_path):\n    img_size = (224, 168)\n    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], \n                                        std=[0.5, 0.5, 0.5])\n    \n    transform = transforms.Compose([transforms.Resize(img_size),\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.ToTensor(),\n                                    normalize\n                                   ])\n    \n    dataset = datasets.ImageFolder(img_path, transform=transform)\n    \n    class_to_idx = dataset.class_to_idx \n    idx_to_class = {v: int(k) for k,v in class_to_idx.items()}\n    \n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False) \n    \n    return dataloader, idx_to_class\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = str(path)  + str(train)  \nprint(img_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader, idx_to_class = (data_loader(img_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(dataloader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = images[0].permute(1, 2, 0)\nimshow(np.asarray(img))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract feature vector for an tensor representing an image\n","metadata":{}},{"cell_type":"code","source":"def gram_matrix(x):\n    n,c,h,w = x.size()\n    x = x.view(n, c, -1)\n    return (x @ x.transpose(1,2))/(c*h*w)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_features(x, feature_extractor, layer_ids, clone=False):\n    features = [feature_extractor[i] for i in layer_ids]\n    hooks = hook_outputs(features, detach=False)\n    feature_extractor(x)\n    features_x = [(o.clone() if clone else o) for o in hooks.stored]\n    return features_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_feature_vector(x, feature_extractor, layer_ids, clone=False):\n    features_x = compute_features(x, feature_extractor, layer_ids, clone)\n    # Computing the Gram Matrix for the features\n    gmv = [gram_matrix(e) for e in features_x]\n    # flat to get single vector\n    gmv_flat_vector = torch.cat([torch.flatten(g) for g in gmv])\n    return gmv_flat_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using a vgg16 network as feature extractor\nvgg_m = vgg16_bn(True).features.cuda().eval()\nvgg_m.requires_grad_(False);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"requires_grad(vgg_m)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# blocks (i.e., layers) to use for the feature extraction\n\nblocks = [i-1 for i,o in enumerate(children_and_parameters(vgg_m)) if isinstance(o,nn.MaxPool2d)]\nblocks, [vgg_m[i] for i in blocks]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images[0].unsqueeze(0).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagesCuda, labelsCuda = images.cuda(), labels.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gmv_flat_vector =[]\nfor i in range(imagesCuda.shape[0]):\n    vector = (compute_feature_vector(imagesCuda[i].unsqueeze(0), vgg_m, blocks))\n    gmv_flat_vector.append(torch.cat([torch.flatten(g) for g in vector]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Class","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(gmv_flat_vector[0] - vector[0]).cpu().norm()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gmv_flat_vector[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(gmv_flat_vector)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}